{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting ASW Kinesis to Databrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark functions\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "# URL processing\n",
    "import urllib\n",
    "\n",
    "# Define the parth\n",
    "delta_table_path = \"dbfs:/user/hive/warehouse/authentication_credentials\"\n",
    "\n",
    "#read the path to spark dataframe\n",
    "access_key_df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "\n",
    "# Retriving the access key and secret keys\n",
    "ACCESS_KEY =access_key_df.select('Access key ID').collect()[0]['Access key ID']\n",
    "SECRET_KEY =access_key_df.select('Secret access key').collect()[0]['Secret access key']\n",
    "ENCODED_SECRET_KEY = urllib.parse.quote(string=SECRET_KEY, safe=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema for the pin table\n",
    "schema_pin = StructType([\n",
    "    StructField(\"index\", IntegerType()),\n",
    "    StructField(\"unique_id\", StringType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"description\", StringType()),\n",
    "    StructField(\"poster_name\", StringType()),\n",
    "    StructField(\"follower_count\", StringType()),\n",
    "    StructField(\"tag_list\", StringType()),\n",
    "    StructField(\"is_image_or_video\", StringType()),\n",
    "    StructField(\"image_src\", StringType()),\n",
    "    StructField(\"downloaded\", IntegerType()),\n",
    "    StructField(\"save_location\", StringType()),\n",
    "    StructField(\"category\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema for the user table\n",
    "schema_user = StructType([\n",
    "    StructField(\"index\", IntegerType()),\n",
    "    StructField(\"first_name\", StringType()),\n",
    "    StructField(\"last_name\", StringType()),\n",
    "    StructField(\"age\", StringType()),\n",
    "    StructField(\"date_joined\", DateType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema for geo table\n",
    "schema_geo = StructType([\n",
    "    StructField(\"index\", IntegerType()),\n",
    "    StructField(\"country\", StringType()),\n",
    "    StructField(\"timestamp\", StringType()),\n",
    "    StructField(\"latitude\", FloatType()),\n",
    "    StructField(\"longitude\", FloatType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Stream data from AWS Kinesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pin data from kinesis using spark\n",
    "df_pin = spark \\\n",
    ".readStream \\\n",
    ".format('kinesis') \\\n",
    ".option('streamName','streaming-0e4753f224a7-pin') \\\n",
    ".option('initialPosition','latest') \\\n",
    ".option('region','us-east-1') \\\n",
    ".option('awsAccessKey', ACCESS_KEY) \\\n",
    ".option('awsSecretKey', SECRET_KEY) \\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of code creates a new DataFrame df_pin from the existing df_pin DataFrame.\n",
    "df_pin = df_pin \\\n",
    "    .withColumn(\"jsonData\", df_pin[\"data\"].cast(\"string\")) \\\n",
    "    .withColumn(\"parsedJson\", from_json(\"jsonData\", schema_pin)) \\\n",
    "    .select(\"parsedJson.*\")\n",
    "\n",
    "display(df_pin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning of pin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rename Index column to ind\n",
    "df_pin = df_pin.withColumnRenamed('Index', 'ind')\n",
    "\n",
    "# Selecting required columns\n",
    "df_pin1 = df_pin.select(['ind', 'unique_id', 'title', 'description', 'follower_count', 'poster_name', 'tag_list', 'is_image_or_video', 'image_src', 'save_location', 'category'])\n",
    "\n",
    "# Clean follower_count and poster_name columns\n",
    "df_pin1 = df_pin1.withColumn('follower_count', regexp_replace(col('follower_count'), 'k', ' '))\n",
    "df_pin1 = df_pin1.withColumn('poster_name', regexp_replace(col('poster_name'), '[^a-zA-Z0-9]', ' '))\n",
    "\n",
    "# Cast follower_count and ind columns to IntegerType\n",
    "df_pin1 = df_pin1.withColumn('follower_count', col('follower_count').cast(IntegerType()))\n",
    "df_pin1 = df_pin1.withColumn('ind', col('ind').cast(IntegerType()))\n",
    "\n",
    "# Filter rows where poster_name is not 'User Info Error' and follower_count is not null\n",
    "df_pin1 = df_pin1.filter((col('poster_name') != 'User Info Error') & (col('follower_count').isNotNull()))\n",
    "\n",
    "# Adjust save_location column\n",
    "df_pin1 = df_pin1.withColumn('save_location', col('save_location').substr(14, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the Pin data to DBFS\n",
    "df_pin1.writeStream \\\n",
    "  .format(\"delta\") \\\n",
    "  .outputMode(\"append\") \\\n",
    "  .option(\"checkpointLocation\", \"/tmp/kinesis/_checkpoints/\") \\\n",
    "  .table(\"0e4753f224a7_pin_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read geo data from kinesis using spark\n",
    "df_geo = spark \\\n",
    ".readStream \\\n",
    ".format('kinesis') \\\n",
    ".option('streamName','streaming-0e4753f224a7-geo') \\\n",
    ".option('initialPosition','latest') \\\n",
    ".option('region','us-east-1') \\\n",
    ".option('awsAccessKey', ACCESS_KEY) \\\n",
    ".option('awsSecretKey', SECRET_KEY) \\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of code creates a new DataFrame df_geo from the existing df_geo DataFrame.\n",
    "\n",
    "df_geo = df_geo \\\n",
    "    .withColumn(\"jsonData\", df_geo[\"data\"].cast(\"string\")) \\\n",
    "    .withColumn(\"parsedJson\", from_json(\"jsonData\", schema_geo)) \\\n",
    "    .select(\"parsedJson.*\")\n",
    "display(df_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning of geo Stream data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'coordinates' column as an array of 'latitude' and 'longitude'\n",
    "df_geo1 = df_geo.withColumn('coordinates', array(col('latitude'), col('longitude')))\n",
    "\n",
    "# Drop 'latitude' and 'longitude' columns\n",
    "df_geo1 = df_geo1.drop('latitude', 'longitude')\n",
    "\n",
    "# Convert 'timestamp' column to timestamp type\n",
    "df_geo1 = df_geo1.withColumn(\"timestamp\", to_timestamp(\"timestamp\", \"yyyy-MM-dd'T'HH:mm:ss\"))\n",
    "\n",
    "# Rename 'index' column to 'ind'\n",
    "df_geo1 = df_geo1.withColumnRenamed(\"index\", 'ind')\n",
    "\n",
    "# Cast 'ind' column to IntegerType\n",
    "df_geo1 = df_geo1.withColumn('ind', col('ind').cast(IntegerType()))\n",
    "\n",
    "# Select specific columns\n",
    "df_geo1 = df_geo1.select('ind', 'country', 'coordinates', 'timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the geo data to DBFS\n",
    "df_geo1.writeStream \\\n",
    "  .format(\"delta\") \\\n",
    "  .outputMode(\"append\") \\\n",
    "  .option(\"checkpointLocation\", \"/tmp/kinesis/_checkpoints/\") \\\n",
    "  .table(\"0e4753f224a7_geo_tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read user data from kinesis using spark\n",
    "df_user = spark \\\n",
    ".readStream \\\n",
    ".format('kinesis') \\\n",
    ".option('streamName','streaming-0e4753f224a7-user') \\\n",
    ".option('initialPosition','latest') \\\n",
    ".option('region','us-east-1') \\\n",
    ".option('awsAccessKey', ACCESS_KEY) \\\n",
    ".option('awsSecretKey', SECRET_KEY) \\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of code creates a new DataFrame df_user from the existing df_user DataFrame.\n",
    "\n",
    "df_user = df_user \\\n",
    "    .withColumn(\"jsonData\", df_user[\"Data\"].cast(\"string\")) \\\n",
    "    .withColumn(\"parsedJson\", from_json(\"jsonData\", schema=schema_user)) \\\n",
    "    .select(\"parsedJson.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning of user stream data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating 'first_name' and 'last_name' into a new column 'user_name'\n",
    "df_user1 = df_user.withColumn('user_name', concat(df_user['first_name'], lit(' '), df_user['last_name']))\n",
    "\n",
    "# Dropping 'first_name' and 'last_name' columns from the DataFrame\n",
    "df_user1 = df_user1.drop('first_name', 'last_name')\n",
    "\n",
    "# Formatting 'date_joined' column to \"yyyy-MM-dd\" format\n",
    "df_user1 = df_user1.withColumn('date_joined', date_format(df_user1['date_joined'], \"yyyy-MM-dd\"))\n",
    "\n",
    "# Converting formatted 'date_joined' column to DateType\n",
    "df_user1 = df_user1.withColumn('date_joined', to_date(df_user1['date_joined']))\n",
    "\n",
    "# Renaming 'index' column to 'ind'\n",
    "df_user1 = df_user1.withColumnRenamed('index', 'ind')\n",
    "\n",
    "# Casting 'ind' column to IntegerType\n",
    "df_user1 = df_user1.withColumn('ind', df_user1['ind'].cast(IntegerType()))\n",
    "\n",
    "# Casting 'age' column to IntegerType\n",
    "df_user1 = df_user1.withColumn('age', df_user1['age'].cast(IntegerType()))\n",
    "\n",
    "# Selecting specific columns ('ind', 'user_name', 'age', 'date_joined') from the DataFrame\n",
    "df_user1 = df_user1.select('ind', 'user_name', 'age', 'date_joined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the user data to DBFS\n",
    "df_user1.writeStream \\\n",
    "  .format(\"delta\") \\\n",
    "  .outputMode(\"append\") \\\n",
    "  .option(\"checkpointLocation\", \"/tmp/kinesis/_checkpoints/\") \\\n",
    "  .table(\"0e4753f224a7_user_table\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
